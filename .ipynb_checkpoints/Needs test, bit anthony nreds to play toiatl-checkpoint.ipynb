{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a46ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numbers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad7990",
   "metadata": {},
   "source": [
    "## Element counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e578318",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "element_list= ['Li', 'Si', 'Mn', 'Fe', 'O', 'Co']\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def get_occ_indices(str_to_search, str_target):\n",
    "    occ_index_list =[]\n",
    "    for index in range(len(str_to_search)):\n",
    "        #print(str_to_search[index:index + len(str_target)])\n",
    "        if str_to_search[index:index + len(str_target)] == str_target:\n",
    "            occ_index_list.append(index)\n",
    "        else:\n",
    "            pass\n",
    "    return occ_index_list\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def get_parentheses(string_with_parentheses):\n",
    "    parentheses_index_list ={}\n",
    "    for o_index in range(len(string_with_parentheses)):\n",
    "        if string_with_parentheses[o_index] == '(':\n",
    "            \n",
    "            \n",
    "            for c_index in range(o_index,len(string_with_parentheses)):\n",
    "                #print(c_index)\n",
    "                \n",
    "                if string_with_parentheses[c_index] == ')':\n",
    "                    #print(c_index)\n",
    "                    \n",
    "                    parentheses_index_list[o_index] = c_index\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    return parentheses_index_list\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def simple_count_in_instance(instance_index, string, element):\n",
    "    counter = 0 \n",
    "    try:\n",
    "        #print(string[instance_index +len(element)])\n",
    "        if string[instance_index +len(element)].isdigit() == False:\n",
    "            counter += 1\n",
    "        elif string[instance_index +len(element)].isdigit() == True:\n",
    "            try:\n",
    "                if string[instance_index +len(element)+1].isdigit() == False:\n",
    "                    counter += int(string[instance_index +len(element)])\n",
    "                elif string[instance_index +len(element)+1].isdigit() == True:\n",
    "                    counter += int(string[instance_index+len(element):instance_index+len(element)+2])\n",
    "            except IndexError:\n",
    "                counter += int(string[instance_index +len(element)])\n",
    "\n",
    "    except IndexError:\n",
    "        counter += 1\n",
    "    return counter\n",
    "\n",
    "################################################################################\n",
    "    \n",
    "def element_count(formula_string):\n",
    "    parenthetical = get_parentheses(formula_string)\n",
    "    \n",
    "    ele_count = {}\n",
    "    for elements in element_list:\n",
    "        \n",
    "        num_ele_n = 0\n",
    "        occurences = get_occ_indices(formula_string, elements)\n",
    "        for instance in occurences:\n",
    "            coeff = 1\n",
    "            inparentheses = False\n",
    "            \n",
    "            close_index = 0\n",
    "            for open_par in parenthetical:\n",
    "               \n",
    "                \n",
    "                if open_par < instance < parenthetical[open_par]:\n",
    "                    inparentheses = True\n",
    "                   \n",
    "                    close_index = parenthetical[open_par]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            if inparentheses == False:\n",
    "                pass\n",
    "              \n",
    "                \n",
    "            else:\n",
    "\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                   \n",
    "                    if formula_string[close_index + 1].isdigit() == True:\n",
    "                        \n",
    "                        \n",
    "                        try:\n",
    "                        \n",
    "                            if formula_string[close_index + 2].isdigit() == True:\n",
    "                                coeff = int(formula_string[close_index + 1:close_index + 3])\n",
    "                               \n",
    "                            else:\n",
    "                                coeff = int(formula_string[close_index + 1])\n",
    "                                \n",
    "                        except IndexError:\n",
    "                            coeff = int(formula_string[close_index + 1])\n",
    "                       \n",
    "                    else:\n",
    "                        coeff = 1\n",
    "                        \n",
    "                except IndexError:\n",
    "                    coeff = 1\n",
    "                \n",
    "               \n",
    "            num_ele_n += simple_count_in_instance(instance, formula_string, elements)*coeff\n",
    "            \n",
    "                  \n",
    "                    \n",
    "        ele_count[elements] = num_ele_n\n",
    "    return ele_count\n",
    "\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25c989",
   "metadata": {},
   "source": [
    "## Decision Tree hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e56571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 15, num = 13)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "parameters_dt = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "def decision_tree_builder(class_or_regress, X_train, y_train):\n",
    "    if class_or_regress == 'classifier':\n",
    "        dt = DecisionTreeClassifier()\n",
    "    else:\n",
    "        dt = DecisionTreeRegressor()\n",
    "    dt_random = RandomizedSearchCV(estimator = dt, param_distributions = parameters_dt, \n",
    "                                   n_iter = 10, cv = 3, verbose = 0, random_state=42, n_jobs = -1)\n",
    "    dt_random.fit(X_train, y_train)\n",
    "    return dt_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9d0e6",
   "metadata": {},
   "source": [
    "## Random forest hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b758ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Random Forest ################################################\n",
    "\n",
    "\n",
    "#using this chunk below, find the best hyperparameters using random search, then output the MSE of crystal system \n",
    "\n",
    "# for first parameter of function, write either \"classifier\" or \"regressor\"\n",
    "# The function will return optimal parameters for whether to bootstrap, max_depth, max_features, min_samples_leaf, \n",
    "# min_samples_split, and n_estimators\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 15, num = 13)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "parameters_rf = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "def random_forest_builder(class_or_regress, X_train, y_train):\n",
    "    if class_or_regress == 'classifier':\n",
    "        rf = RandomForestClassifier()\n",
    "    else:\n",
    "        rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = parameters_rf, \n",
    "                                   n_iter = 10, cv = 3, verbose = 0, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    return rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172e70b",
   "metadata": {},
   "source": [
    "## Boosting Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d5c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimators in GBC    \n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 15, num = 13)]\n",
    "max_depth.append(None)\n",
    "# Learning rate\n",
    "learning_rate = [0.001,0.001,0.01,0.1]\n",
    "\n",
    "parameters_gbc = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'learning_rate': learning_rate}\n",
    "\n",
    "def gradient_boosting_builder(class_or_regress, X_train, y_train):\n",
    "    if class_or_regress == 'classifier':\n",
    "        gbc = GradientBoostingClassifier()\n",
    "    else:\n",
    "        gbc = GradientBoostingRegressor()\n",
    "    gbc_random = RandomizedSearchCV(estimator = gbc, param_distributions = parameters_gbc, \n",
    "                                   n_iter = 10, cv = 3, verbose = 0, random_state=42, n_jobs = -1)\n",
    "    gbc_random.fit(X_train, y_train)\n",
    "    return gbc_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62f3a2",
   "metadata": {},
   "source": [
    "### Getting MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16e391d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula ='default'\n",
    "formation_e = ''\n",
    "bandgap_input = ''\n",
    "Nsites = ''\n",
    "Density = ''\n",
    "Volume=''\n",
    "\n",
    "\n",
    "\n",
    "formation_e = '11'\n",
    "bandgap_input = '1'\n",
    "Nsites = '1'\n",
    "Density = '1'\n",
    "Volume = ''\n",
    " \n",
    "######################## DONT MESS WITH THIS  ########################\n",
    "\n",
    "\n",
    "def model_maker_score(formula ='default',formation_e = '',bandgap_input = '', Nsites = '',Density = '',Volume=''):\n",
    "\n",
    "    BigDataEnergy = pd.read_csv(r'lithium-ion batteries.csv')\n",
    "    BigDataEnergy2 = BigDataEnergy[['Formation Energy (eV)', 'Band Gap (eV)','Nsites','Density (gm/cc)','Volume','Crystal System']].copy()\n",
    "\n",
    "    permutations_list = []\n",
    "\n",
    "    for i in range(0,len(BigDataEnergy['Formula'])):\n",
    "        permutations_list.append(element_count(BigDataEnergy['Formula'][i]))\n",
    "\n",
    "    formula_split = pd.DataFrame(permutations_list)\n",
    "\n",
    "    concatenated_dataframes = pd.concat([formula_split, BigDataEnergy2], axis=1)\n",
    "\n",
    "    stock_inputs = ['Formation Energy (eV)','Band Gap (eV)','Nsites','Density (gm/cc)','Volume']\n",
    "    input_list = []\n",
    "\n",
    "        \n",
    "    if formation_e != '':\n",
    "        input_list.append('Formation Energy (eV)')\n",
    "\n",
    "    if bandgap_input != '':\n",
    "        input_list.append('Band Gap (eV)')\n",
    "\n",
    "    if Nsites != '':\n",
    "        input_list.append('Nsites')\n",
    "\n",
    "    if Density != '':\n",
    "        input_list.append('Density (gm/cc)')\n",
    "\n",
    "    if Volume != '':\n",
    "        input_list.append('Volume')\n",
    "\n",
    "    found = set(input_list) & set(stock_inputs)\n",
    "    output_list = list(set(stock_inputs) - found)\n",
    "\n",
    "    input_df = pd.concat([formula_split, BigDataEnergy2[input_list]], axis=1)\n",
    "    output_df = pd.concat([BigDataEnergy2[output_list],BigDataEnergy2['Crystal System']], axis=1)\n",
    "    \n",
    "    \n",
    "    ############  Ohh hey do the model training\n",
    "    \n",
    "    return input_df, output_df\n",
    "\n",
    "\n",
    "\n",
    "input_df, output_df = model_maker_score(formation_e = '1',bandgap_input = '1', Nsites = '1',Density = '1',Volume='1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36be35b",
   "metadata": {},
   "source": [
    "## Score finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5f04f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Crystal System': 0.625}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_finder(input_df, output_df):\n",
    "    \n",
    "    score_dict_Tree = {}\n",
    "    score_dict_Forest = {}\n",
    "    score_dict_Boosting = {}\n",
    "\n",
    "    for i in range(0,len(output_df.columns)):\n",
    "        print(i)\n",
    "        if output_df.columns[i] != 'Crystal System':\n",
    "            X_train, X_test, y_train, y_test = train_test_split(input_df, output_df[output_df.columns[i]], test_size=0.10, random_state=42)\n",
    "\n",
    "            params = random_forest_builder('regressor', X_train, y_train)\n",
    "            reg_Forest = RandomForestRegressor( \n",
    "                n_estimators = params['n_estimators'],\n",
    "                min_samples_split = params['min_samples_split'],\n",
    "                min_samples_leaf = params['min_samples_leaf'],\n",
    "                max_features = params['max_features'],\n",
    "                max_depth = params['max_depth'],\n",
    "                bootstrap = params['bootstrap'])\n",
    "            score_Forest =np.round(cross_validate(reg_Forest, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "\n",
    "            params = gradient_boosting_builder('regressor', X_train, y_train)\n",
    "            reg_Boosting = GradientBoostingRegressor(n_estimators = params['n_estimators'],\n",
    "                max_depth = params['max_depth'],\n",
    "                learning_rate = params['learning_rate'])\n",
    "            score_Boosting = np.round(cross_validate(reg_Boosting, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "            params = decision_tree_builder('regressor', X_train, y_train)\n",
    "            reg_Tree = DecisionTreeRegressor(\n",
    "                min_samples_split = params['min_samples_split'],\n",
    "                min_samples_leaf = params['min_samples_leaf'],\n",
    "                max_features = params['max_features'],\n",
    "                max_depth = params['max_depth'])\n",
    "            score_Tree = np.round(cross_validate(reg_Tree, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "        else: \n",
    "            X_train, X_test, y_train, y_test = train_test_split(input_df, output_df[output_df.columns[i]], test_size=0.10, random_state=42)\n",
    "\n",
    "            params = random_forest_builder('classifier', X_train, y_train)\n",
    "            reg_Forest = RandomForestClassifier( \n",
    "                n_estimators = params['n_estimators'],\n",
    "                min_samples_split = params['min_samples_split'],\n",
    "                min_samples_leaf = params['min_samples_leaf'],\n",
    "                max_features = params['max_features'],\n",
    "                max_depth = params['max_depth'],\n",
    "                bootstrap = params['bootstrap'])\n",
    "            score_Forest =np.round(cross_validate(reg_Forest, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "            params = gradient_boosting_builder('classifier', X_train, y_train)\n",
    "            reg_Boosting = GradientBoostingClassifier(n_estimators = params['n_estimators'],\n",
    "                max_depth = params['max_depth'],\n",
    "                learning_rate = params['learning_rate'])\n",
    "            score_Boosting = np.round(cross_validate(reg_Boosting, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "            params = decision_tree_builder('classifier', X_train, y_train)\n",
    "            reg_Tree = DecisionTreeClassifier(\n",
    "                min_samples_split = params['min_samples_split'],\n",
    "                min_samples_leaf = params['min_samples_leaf'],\n",
    "                max_features = params['max_features'],\n",
    "                max_depth = params['max_depth'])\n",
    "            score_Tree = np.round(cross_validate(reg_Tree, X_train, y_train, cv=3)['test_score'].mean(),3)\n",
    "\n",
    "\n",
    "        score_dict_Tree[output_df.columns[i]] = score_Tree\n",
    "        score_dict_Boosting[output_df.columns[i]] = score_Boosting\n",
    "        score_dict_Forest[output_df.columns[i]] = score_Forest\n",
    "\n",
    "        ratings=[score_dict_Tree,score_dict_Boosting,score_dict_Forest]\n",
    "\n",
    "    Overall_score = {}\n",
    "\n",
    "    for i in range(0,len(list(ratings[0].keys()))):\n",
    "        key_name = list(ratings[0].keys())[i]\n",
    "        Overall_score[key_name] = np.round(np.mean([score_dict_Tree[key_name],score_dict_Boosting[key_name],score_dict_Forest[key_name]]),3)\n",
    "\n",
    "    return Overall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4f827",
   "metadata": {},
   "source": [
    "## Anthony Work On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8bc1e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For inputs of: {'Li': 2, 'Si': 3, 'Mn': 1, 'Fe': 0, 'O': 8, 'Co': 0}\n",
      "+---------------+--------------+--------------+---------------+----------------+---------------+----------------+\n",
      "|    Field 1    |   Field 2    |   Field 3    |    Field 4    |    Field 5     |    Field 6    |    Field 7     |\n",
      "+---------------+--------------+--------------+---------------+----------------+---------------+----------------+\n",
      "|  RandomForest | [2.6781331]  | [2.76805982] | [-2.86760833] | [400.89172443] | [33.36306062] | ['monoclinic'] |\n",
      "|    Boosting   | [2.62875817] | [2.85667258] | [-2.86233654] | [463.70379206] | [37.30131975] | ['monoclinic'] |\n",
      "| Decision Tree |  [2.67575]   |   [2.9985]   |   [-2.8695]   | [428.29282418] | [42.75675676] | ['monoclinic'] |\n",
      "+---------------+--------------+--------------+---------------+----------------+---------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "x = PrettyTable()\n",
    "\n",
    "formula ='default'\n",
    "formation_e = ''\n",
    "bandgap_input = ''\n",
    "Nsites = ''\n",
    "Density = ''\n",
    "Volume=''\n",
    "\n",
    "test_formula = 'Li2MnSi3O8'\n",
    "test_formula = element_count(test_formula)\n",
    "\n",
    "tester_input = pd.DataFrame(data=[test_formula])\n",
    "\n",
    "formation_e = ''\n",
    "bandgap_input = ''\n",
    "Nsites = ''\n",
    "Density = ''\n",
    "Volume = ''\n",
    " \n",
    "\n",
    "\n",
    "MSE_list_Forest = []\n",
    "MSE_list_Boosting = []\n",
    "MSE_list_Tree = []\n",
    "\n",
    "for i in range(0,len(output_df.columns)):\n",
    "    \n",
    "    if output_df.columns[i] != 'Crystal System':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_df, output_df[output_df.columns[i]], test_size=0.10, random_state=42)\n",
    "\n",
    "        params = random_forest_builder('regressor', X_train, y_train)\n",
    "        reg_Forest = RandomForestRegressor( \n",
    "            n_estimators = params['n_estimators'],\n",
    "            min_samples_split = params['min_samples_split'],\n",
    "            min_samples_leaf = params['min_samples_leaf'],\n",
    "            max_features = params['max_features'],\n",
    "            max_depth = params['max_depth'],\n",
    "            bootstrap = params['bootstrap']).fit(X_train, y_train)\n",
    "        y_predict_Forest = reg_Forest.predict(tester_input)\n",
    "        MSE_Forest = y_predict_Forest\n",
    "        \n",
    "        \n",
    "        \n",
    "        params = gradient_boosting_builder('regressor', X_train, y_train)\n",
    "        reg_Boosting = GradientBoostingRegressor(n_estimators = params['n_estimators'],\n",
    "            max_depth = params['max_depth'],\n",
    "            learning_rate = params['learning_rate']).fit(X_train, y_train)\n",
    "        y_predict_Boosting = reg_Boosting.predict(tester_input)\n",
    "        MSE_Boosting = y_predict_Boosting\n",
    "\n",
    "        params = decision_tree_builder('regressor', X_train, y_train)\n",
    "        reg_Tree = DecisionTreeRegressor(\n",
    "            min_samples_split = params['min_samples_split'],\n",
    "            min_samples_leaf = params['min_samples_leaf'],\n",
    "            max_features = params['max_features'],\n",
    "            max_depth = params['max_depth']).fit(X_train, y_train)\n",
    "        y_predict_Tree = reg_Tree.predict(tester_input)\n",
    "        MSE_Tree = y_predict_Tree\n",
    "        \n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_df, output_df[output_df.columns[i]], test_size=0.10, random_state=42)\n",
    "\n",
    "        params = random_forest_builder('classifier', X_train, y_train)\n",
    "        reg_Forest = RandomForestClassifier( \n",
    "            n_estimators = params['n_estimators'],\n",
    "            min_samples_split = params['min_samples_split'],\n",
    "            min_samples_leaf = params['min_samples_leaf'],\n",
    "            max_features = params['max_features'],\n",
    "            max_depth = params['max_depth'],\n",
    "            bootstrap = params['bootstrap']).fit(X_train, y_train)\n",
    "        y_predict_Forest = reg_Forest.predict(tester_input)\n",
    "        MSE_Forest = y_predict_Forest\n",
    "        \n",
    "        params = gradient_boosting_builder('classifier', X_train, y_train)\n",
    "        reg_Boosting = GradientBoostingClassifier(n_estimators = params['n_estimators'],\n",
    "            max_depth = params['max_depth'],\n",
    "            learning_rate = params['learning_rate']).fit(X_train, y_train)\n",
    "        y_predict_Boosting = reg_Boosting.predict(tester_input)\n",
    "        MSE_Boosting = y_predict_Boosting\n",
    "\n",
    "        params = decision_tree_builder('classifier', X_train, y_train)\n",
    "        reg_Tree = DecisionTreeClassifier(\n",
    "            min_samples_split = params['min_samples_split'],\n",
    "            min_samples_leaf = params['min_samples_leaf'],\n",
    "            max_features = params['max_features'],\n",
    "            max_depth = params['max_depth']).fit(X_train, y_train)\n",
    "        y_predict_Tree = reg_Tree.predict(tester_input)\n",
    "        MSE_Tree = y_predict_Tree\n",
    "        \n",
    "        \n",
    "        \n",
    "    MSE_list_Forest.append(MSE_Forest)\n",
    "    MSE_list_Boosting.append(MSE_Boosting)\n",
    "    MSE_list_Tree.append(MSE_Tree)\n",
    "\n",
    "x.add_row(['RandomForest'] + MSE_list_Forest)\n",
    "x.add_row(['Boosting'] + MSE_list_Boosting)\n",
    "x.add_row(['Decision Tree'] + MSE_list_Tree)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "######################## fancy ################################################\n",
    "print('For inputs of:', test_formula)\n",
    "print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
